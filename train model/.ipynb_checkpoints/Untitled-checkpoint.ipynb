{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1188045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_22208\\3665540914.py:11: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  mpl.style.use(\"seaborn-darkgrid\")\n"
     ]
    }
   ],
   "source": [
    "# import all library required\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# style your matplotlib\n",
    "mpl.style.use(\"seaborn-darkgrid\")\n",
    "# run this block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92477380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # show progress bar of for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cfa7d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of files in train folder\n",
    "files=os.listdir(\"C:/Users/Asus/Desktop/project_app_mobile/input/mma-facial-expression/MMAFEDB/train/\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62169b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6566/6566 [00:45<00:00, 143.02it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3231/3231 [00:23<00:00, 136.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4859/4859 [00:35<00:00, 137.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 18000/18000 [02:15<00:00, 132.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 18000/18000 [02:13<00:00, 134.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 12223/12223 [01:18<00:00, 156.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8113/8113 [00:50<00:00, 161.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# now create image and label array\n",
    "image_array=[]  # it's a list later i will convert it to array\n",
    "label_array=[]\n",
    "path=\"C:/Users/Asus/Desktop/project_app_mobile/input/mma-facial-expression/MMAFEDB/train/\"\n",
    "# loop through each sub-folder in train\n",
    "for i in range(len(files)):\n",
    "    # files in sub-folder\n",
    "    file_sub=os.listdir(path+files[i])\n",
    "\n",
    "   # print(len(file_sub))\n",
    "    # loop through each files\n",
    "    \n",
    "    # for neutral and happy dataset we will use only 18000 image\n",
    "    if(files[i]==\"neutral\" or files[i]==\"happy\"):\n",
    "        for k in tqdm(range(18000)):\n",
    "            # read image\n",
    "            img=cv2.imread(path+files[i]+\"/\"+file_sub[k])\n",
    "            # convert image from BGR to RGB\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            # append image_array with img\n",
    "            image_array.append(img)\n",
    "            label_array.append(i)\n",
    "            # i is interger from 0-6\n",
    "            # run this block\n",
    "    else:\n",
    "        # for other all \n",
    "        for k in tqdm(range(len(file_sub))):\n",
    "            # read image\n",
    "            img=cv2.imread(path+files[i]+\"/\"+file_sub[k])\n",
    "            # convert image from BGR to RGB\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            # append image_array with img\n",
    "            image_array.append(img)\n",
    "            label_array.append(i)\n",
    "            # i is interger from 0-6\n",
    "            # run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c045457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b=np.unique(label_array,return_counts=\"True\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bb518c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6566,  3231,  4859, 18000, 18000, 12223,  8113], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b\n",
    "# due to low ram memory we have to reduce our training dataset\n",
    "# we will reduce 29384,28592 to 18000\n",
    "# this will solve low memory issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2fe3057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now use this to free some ram memory\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04a414d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.66 GiB for an array with shape (70992, 48, 48, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# now divide image_array by 255.0\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# this wil scale image pixel from 0-255 to 0-1\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m image_array\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(image_array)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# convert label list to array\u001b[39;00m\n\u001b[0;32m      5\u001b[0m label_array\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(label_array)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.66 GiB for an array with shape (70992, 48, 48, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "# now divide image_array by 255.0\n",
    "# this wil scale image pixel from 0-255 to 0-1\n",
    "image_array=np.array(image_array)/255.0\n",
    "# convert label list to array\n",
    "label_array=np.array(label_array)\n",
    "# run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85eadddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now define label_to_text \n",
    "#['surprise', 'fear', 'angry', 'neutral', 'sad', 'disgust', 'happy']\n",
    "label_to_text={0:\"surprise\",1:\"fear\",2:\"angry\",3:\"neutral\",4:\"sad\",5:\"disgust\",6:\"happy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "123a435f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this dic can convert label to text_label\n",
    "# example\n",
    "label_to_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ea87601",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.29 GiB for an array with shape (63892, 48, 48, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m image_array,X_test,Y_train,Y_test\u001b[38;5;241m=\u001b[39mtrain_test_split(image_array,label_array,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# you can change test size \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# we are using 10% for validation\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#now before running this block change X_train to image_array to save ram memory\u001b[39;00m\n\u001b[0;32m      7\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2585\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2581\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2583\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m-> 2585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2586\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2587\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2581\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2583\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2586\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:356\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:185\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    184\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array[key] \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.29 GiB for an array with shape (63892, 48, 48, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "image_array,X_test,Y_train,Y_test=train_test_split(image_array,label_array,test_size=0.1)\n",
    "# you can change test size \n",
    "# we are using 10% for validation\n",
    "\n",
    "#now before running this block change X_train to image_array to save ram memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9e11c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see image and label\n",
    "# define dic for converting label to test_label\n",
    "#['surprise', 'fear', 'angry', 'neutral', 'sad', 'disgust', 'happy']\n",
    "label_to_text={0:\"surprise\",1:\"fear\",2:\"angry\",3:\"neutral\",4:\"sad\",5:\"disgust\",6:\"happy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a03959b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angry'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5fedfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     12\u001b[0m idx\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m show_examples(image_array,Y_train,idx)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# define a function \n",
    "def show_examples(image,label,idx):\n",
    "    # create 4x4 figure\n",
    "    fig,axes=plt.subplots(nrows=4,ncols=4,figsize=(16,16))\n",
    "    # loop through each figure\n",
    "    for idx_f,ax in zip(idx,axes.ravel()):\n",
    "        # add image to figure\n",
    "        ax.imshow(image[idx_f].squeeze(),cmap=\"gray\")\n",
    "        # add title to each figure\n",
    "        ax.set_title(label_to_text[label[idx_f]])\n",
    "    plt.show()\n",
    "idx=np.random.choice(16,16)\n",
    "show_examples(image_array,Y_train,idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51033302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will start with our model\n",
    "# import all library required for model\n",
    "from keras import layers,callbacks,utils,applications,optimizers\n",
    "from keras.models import Sequential,Model,load_model\n",
    "# run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "111e3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 8s 1us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Func  (None, 2, 2, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2259265 (8.62 MB)\n",
      "Trainable params: 2225153 (8.49 MB)\n",
      "Non-trainable params: 34112 (133.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "# I will use MobileNetV2 as an pretrained model \n",
    "pretrained_model=applications.MobileNetV2(input_shape=(48,48,3),include_top=False,\n",
    "                                         weights=\"imagenet\")\n",
    "# you can use other pretrained model to increase accuracy or increase frame rate\n",
    "# change all non-trainable layer to trainable\n",
    "pretrained_model.trainable=True\n",
    "# add pretrained_model to model\n",
    "model.add(pretrained_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "# add dropout to increase accuracy by not overfitting\n",
    "model.add(layers.Dropout(0.3))\n",
    "# add dense layer as final output\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "702ee493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1fb2fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "\n",
    "model.compile(optimizer=Adam(0.0001),loss=\"mean_squared_error\",metrics=[\"mae\"])\n",
    "# run\n",
    "# starting learning rate is 1e-3\n",
    "# you can change optimizer, loss function, metrics for better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3387f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model checkpoint to save model\n",
    "ckp_path=\"trained_model/model\"\n",
    "model_checkpoint=tf.keras.callbacks.ModelCheckpoint(filepath=ckp_path,\n",
    "                                                   monitor=\"val_mae\",\n",
    "                                                   save_best_only=True,\n",
    "                                                   save_weights_only=True,\n",
    "                                                   mode=\"auto\")\n",
    "# this checkpoint save model when val_mae is lower then best val_mae\n",
    "#run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62470a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will define learning rate reducer \n",
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(factor=0.9,\n",
    "                                              monitor=\"val_mae\",\n",
    "                                              mode=\"auto\",\n",
    "                                              cooldown=0,\n",
    "                                              patience=5,\n",
    "                                              verbose=1,\n",
    "                                              min_lr=1e-6)\n",
    "# this will decrease learning rate when val_mae does't decrease durning last 5 epoch\n",
    "# verbose is use to show val_mae every epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=5 #real epochs is 300\n",
    "BATCH_SIZE=64\n",
    "# start training\n",
    "history=model.fit(image_array,Y_train,\n",
    "                 validation_data=(X_test,Y_test),\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 epochs=EPOCHS,\n",
    "                 callbacks=[model_checkpoint,reduce_lr])\n",
    "#run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after training is finished \n",
    "# load best model\n",
    "model.load_weights(ckp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdab4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see result\n",
    "prediction_val=model.predict(X_test,batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction value \n",
    "prediction_val[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original value\n",
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert model to tensorflow lite model \n",
    "converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model=converter.convert()\n",
    "\n",
    "#save model \n",
    "with open(\"model.tflite\",\"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
